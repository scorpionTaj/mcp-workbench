# MCP Workbench

<div align="center">
  
  ### ğŸš€ Modern, High-Performance Interface for Multi-Provider LLM Chat, MCP Tools & Data Science

[![Next.js 16](https://img.shields.io/badge/Next.js-16-black?logo=next.js)](https://nextjs.org/)
[![React 19](https://img.shields.io/badge/React-19-61dafb?logo=react)](https://react.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.9-blue?logo=typescript)](https://www.typescriptlang.org/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind-4.1-38bdf8?logo=tailwind-css)](https://tailwindcss.com/)
[![Prisma](https://img.shields.io/badge/Prisma-Latest-2D3748?logo=prisma)](https://www.prisma.io/)

  <p>
    <a href="#-key-features">Features</a> â€¢
    <a href="#-screenshots">Screenshots</a> â€¢
    <a href="#-getting-started">Getting Started</a> â€¢
    <a href="#%EF%B8%8F-tech-stack">Tech Stack</a> â€¢
    <a href="#-supported-providers">Providers</a>
  </p>
  
</div>

---

## ğŸ“– Overview

**MCP Workbench** is a comprehensive, production-ready application that provides a unified interface for working with **11+ LLM Providers**, **Model Context Protocol (MCP) servers**, and **data science tools**. Built with cutting-edge web technologies and optimized for peak performance, it delivers a seamless developer experience with premium UI/UX and enterprise-grade security.

### ğŸ¯ Project Highlights

| Metric              | Achievement                                     |
| ------------------- | ----------------------------------------------- |
| **Providers**       | 11+ providers (Local + Remote) with unified API |
| **Performance**     | 66% faster operations with smart caching        |
| **Security**        | 160+ blocked patterns for safe code execution   |
| **User Experience** | Premium animations & glassmorphism design       |
| **Developer Tools** | Auto Python detection & integrated terminal     |
| **Reliability**     | Error boundaries & comprehensive error handling |

---

## âœ¨ What's New in v3.0

<table>
<tr>
<td width="50%">

### ğŸŒ Multi-Provider Support

- ğŸ¯ **11 LLM Providers** (3 local + 8 remote)
- ğŸ”‘ **Database-backed API keys** (secure storage)
- ğŸ”„ **Health monitoring** for all providers
- ğŸ¨ **Provider management UI** with status indicators
- ğŸ“Š **Model selection** across all providers
- ğŸš€ **One-click chat** from models page

</td>
<td width="50%">

### ğŸ”’ Security Features

- ğŸ›¡ï¸ **Terminal protection**: 60+ blocked patterns
- ğŸ **Python sandbox**: 100+ blocked patterns
- âœ… **Whitelist mode**: Safe libraries only
- ğŸ” **Output sanitization**: Removes sensitive data
- ğŸ“ **Security dashboard**: Real-time monitoring
- âš ï¸ **Detailed warnings**: Clear error messages

</td>
</tr>
<tr>
<td width="50%">

### ğŸš€ Performance Improvements

- âš¡ **66% faster** registry operations
- âš¡ **40% faster** page renders
- âš¡ **70%** reduction in network requests
- ğŸ”„ Smart deduplication & retry logic
- ğŸ’¾ Optimized SWR caching (60s intervals)

</td>
<td width="50%">

### ğŸ¨ UI/UX Enhancements

- ğŸ­ Premium glassmorphism design
- âœ¨ Staggered card reveal animations
- ğŸŒŠ Smooth scrolling everywhere
- ğŸ¯ Enhanced provider cards
- ğŸ” Advanced filtering & search
- ğŸ“± Fully responsive layout

</td>
</tr>
<tr>
<td width="50%">

### ğŸ Python Integration

- ğŸ” **Auto-detect**: uv, miniforge3, conda, venv
- ğŸ’» **Integrated terminal** with security
- ğŸ“œ **Command history** (â†‘â†“ navigation)
- ğŸ” **Sandboxed execution** for safety
- âš™ï¸ **Manual configuration** support
- ğŸ¯ **Environment selector** in Settings

</td>
<td width="50%">

### ğŸ›¡ï¸ Reliability Features

- ğŸ”’ Global error boundaries
- ğŸ”” Toast notifications (4 types)
- â³ Skeleton loading states
- ğŸ”„ Automatic retry logic
- ğŸ› Enhanced error messages
- ğŸ“Š Connection diagnostics

</td>
</tr>
</table>

---

## ğŸŒ Supported Providers

### Local Providers (3)

| Provider         | Description             | Health Check    | Models API      |
| ---------------- | ----------------------- | --------------- | --------------- |
| ğŸ¦™ **Ollama**    | Open-source LLM runtime | âœ… `/api/tags`  | âœ… `/api/tags`  |
| ğŸ¬ **LM Studio** | Local model server      | âœ… `/v1/models` | âœ… `/v1/models` |
| âš™ï¸ **Custom**    | Your own endpoint       | âš™ï¸ Configurable | âš™ï¸ Configurable |

### Remote Providers (8)

| Provider           | Description                  | API Key Required      | Models Count |
| ------------------ | ---------------------------- | --------------------- | ------------ |
| ğŸ¤– **OpenAI**      | GPT-4, GPT-3.5               | âœ… OPENAI_API_KEY     | 20+          |
| ğŸ§  **Anthropic**   | Claude 3.5 Sonnet/Opus/Haiku | âœ… ANTHROPIC_API_KEY  | 5+           |
| ğŸ”® **Google AI**   | Gemini 2.5 Flash/Pro         | âœ… GOOGLE_API_KEY     | 10+          |
| âš¡ **Groq**        | Ultra-fast inference         | âœ… GROQ_API_KEY       | 8+           |
| ğŸŒ **OpenRouter**  | Access 100+ models           | âœ… OPENROUTER_API_KEY | 100+         |
| ğŸ¤ **Together AI** | Open-source models           | âœ… TOGETHER_API_KEY   | 50+          |
| ğŸ§ª **Mistral AI**  | Mistral models               | âœ… MISTRAL_API_KEY    | 8+           |
| ğŸ’¬ **Cohere**      | Command models               | âœ… COHERE_API_KEY     | 5+           |

### ğŸ”‘ API Key Management

- **Database Storage**: All API keys stored securely in SQLite
- **Environment Variables**: Fallback to `.env` for compatibility
- **UI Configuration**: Add/update keys through Providers page
- **Per-Provider**: Each provider can have its own key
- **Validation**: Automatic health checks verify connectivity

---

## ğŸ“¸ Screenshots

### ğŸ›ï¸ Dashboard - Real-time Monitoring

![Dashboard](./Screenshots/Dashboard.png)

> Monitor Ollama, LM Studio, and MCP servers with animated status cards showing real-time health metrics

### ğŸ’¬ Chat Interface - Full-Featured LLM Chat

![Chat Interface 1](./Screenshots/Chat1.png)

![Chat Interface 2](./Screenshots/Chat2.png)

> Persistent chat history, seamless model switching, tool integration, and syntax-highlighted code blocks with advanced debugging inspector

### ğŸ“š Registry - Discover & Install MCP Servers

![Registry](./Screenshots/Registry.png)

> Browse 100+ MCP servers from GitHub with advanced filtering by tags, languages, and search

### ï¿½ï¸ Tools - MCP Server Management

![Tools](./Screenshots/Tools.png)

> Manage and monitor all installed MCP servers with detailed status information

### ğŸ¤– Models - Multi-Provider LLM Management

![Models](./Screenshots/Models.png)

> Browse and manage models from all providers (Ollama, LM Studio, OpenAI, Anthropic, Google, etc.) with one-click chat integration, reasoning detection, and advanced filtering

### ğŸ’¬ Chat - Multi-Provider Chat Interface

![Chat Interface 1](./Screenshots/Chat1.png)

![Chat Interface 2](./Screenshots/Chat2.png)

> Unified chat interface supporting all 11 providers with persistent history, seamless model switching, tool integration, and syntax-highlighted code blocks with advanced debugging inspector

### ğŸ Notebook - Python Development Environment

![Notebook](./Screenshots/Notebook.png)

> Execute Python code with auto-detected environments, rich output rendering, and artifact management

### âš™ï¸ Python Environment Selector & Integrated Terminal

![Python Selector + Terminal](./Screenshots/Python%20Selector%20+%20Terminal.png)

> Automatic detection of system Python, conda environments, and virtual environments with integrated terminal for command execution

### ï¿½ Datasets - Data Management

![Datasets](./Screenshots/Datasets.png)

> Upload, preview, and manage datasets for data science workflows

### ğŸ”§ MCP Configuration - Visual Editor

![MCP Config Visual](./Screenshots/MCP%20Config%20Visual.png)

> Visual editor for MCP server configuration with environment variable management

### ğŸ“ MCP Configuration - JSON Editor

![MCP Config JSON](./Screenshots/MCP%20Config%20Json.png)

> Direct JSON editing for advanced MCP server configuration with syntax highlighting

---

## ğŸ¯ Key Features

### Core Functionality

<table>
<tr>
<td width="33%">

#### ğŸ›ï¸ Dashboard

- Real-time provider monitoring
- Health status indicators
- Animated status cards
- Connection diagnostics
- Quick actions

</td>
<td width="33%">

#### ğŸ’¬ Chat

- **11 LLM providers** support
- Persistent history
- **One-click model selection**
- Tool integration
- Code highlighting
- Markdown rendering
- **Multi-provider switching**

</td>
<td width="33%">

#### ğŸ“Š Models

- Browse **all provider models**
- **Quick chat button**
- Reasoning detection
- Model metadata
- Advanced filtering
- Provider grouping
- Sorting options

</td>
</tr>
<tr>
<td width="33%">

#### ğŸ“š Registry

- 100+ MCP servers
- GitHub integration
- Tag filtering
- One-click install
- Version tracking

</td>
<td width="33%">

#### ğŸ”§ Tools

- Manage MCP servers
- View capabilities
- Configuration UI
- Status monitoring
- Quick actions

</td>
<td width="33%">

#### ğŸ“ Datasets

- CSV/Parquet upload
- Data preview
- Vector indexing
- Column analysis
- Export options

</td>
</tr>
<tr>
<td width="33%">

#### ğŸ Notebook

- Python execution
- Environment detection
- Rich output
- Image rendering
- Artifact export

</td>
<td width="33%">

#### ğŸ’» Terminal

- Command execution
- Syntax highlighting
- Command history
- Security features
- Output capture

</td>
<td width="33%">

#### âŒ¨ï¸ Command Palette

- Quick navigation
- Keyboard shortcuts
- Action search
- Recent items
- Context aware

</td>
</tr>
</table>

---

## ğŸš€ Getting Started

### Prerequisites

Ensure you have the following installed:

- **Node.js** 20+ ([Download](https://nodejs.org/))
- **bun** (recommended) or npm
  ```bash
  npm install -g bun
  ```
- **(Optional) Local LLM Providers**:
  - [Ollama](https://ollama.ai/) - Free, open-source
  - [LM Studio](https://lmstudio.ai/) - User-friendly GUI
- **(Optional) Remote Providers**: Get API keys from:
  - [OpenAI](https://platform.openai.com/) - GPT-4, GPT-3.5
  - [Anthropic](https://console.anthropic.com/) - Claude models
  - [Google AI Studio](https://aistudio.google.com/) - Gemini models
  - [Groq](https://console.groq.com/) - Ultra-fast inference
  - [OpenRouter](https://openrouter.ai/) - Access 100+ models
  - [Together AI](https://together.ai/) - Open-source models
  - [Mistral AI](https://console.mistral.ai/) - Mistral models
  - [Cohere](https://dashboard.cohere.com/) - Command models
- **Python 3.8+** (optional, for Notebook - auto-detected!)

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/scorpiontaj/mcp-workbench.git
   cd mcp-workbench
   ```

2. **Install dependencies**

   ```bash
   bun install
   ```

3. **Set up environment variables**

   ```bash
   cp .env.example .env.local
   ```

   Edit `.env.local` and configure:

   ```env
   # Database
   DATABASE_URL="file:./dev.db"

   # Local Providers (Optional)
   OLLAMA_BASE_URL="http://localhost:11434"
   LM_STUDIO_BASE_URL="http://localhost:1234"

   # Remote Providers (Optional - Can also be set via UI)
   OPENAI_API_KEY="sk-..."
   ANTHROPIC_API_KEY="sk-ant-..."
   GOOGLE_API_KEY="AI..."
   GROQ_API_KEY="gsk_..."
   OPENROUTER_API_KEY="sk-or-..."
   TOGETHER_API_KEY="..."
   MISTRAL_API_KEY="..."
   COHERE_API_KEY="..."
   ```

   > **Note**: API keys can also be configured through the UI in **Settings â†’ Providers**

4. **Initialize the database**

   ```bash
   bun db:push
   bun db:seed
   ```

5. **Run the development server**

   ```bash
   bun dev
   ```

6. **Open your browser**

   Navigate to [http://localhost:3000](http://localhost:3000)

### Quick Start Guide

#### ğŸŒ Setting Up Providers

1. **Via UI (Recommended)**:

   - Go to **Settings â†’ Providers**
   - Click on any provider card
   - Enter your API key
   - Save and test connection

2. **Via Environment Variables**:
   - Add keys to `.env.local` (see Installation step 3)
   - Restart the server

#### ğŸ¤– Using Models

1. Go to **Models** page
2. Browse models from all connected providers
3. Click **"Use in Chat"** on any model
4. Start chatting immediately!

#### ğŸ Python Environment Setup

1. Go to **Settings â†’ Python**
2. Click **"Select Python Environment"**
3. Choose from auto-detected environments:
   - System Python
   - uv Python
   - Conda/Miniforge3 environments
   - Virtual environments
4. Or add custom path
5. Start coding in the Notebook!

#### ğŸ’» Using the Terminal

1. Open **Notebook â†’ Settings**
2. Terminal is ready at the bottom
3. Type commands and press **Enter**
4. Use **â†‘â†“** for history, **Ctrl+L** to clear

**Example Commands:**

```bash
python --version
pip list
pip install numpy pandas matplotlib
python -c "import numpy; print(numpy.__version__)"
```

#### ğŸ”’ Security Features

MCP Workbench includes enterprise-grade security:

- âœ… **160+ blocked command/code patterns**
- âœ… **Whitelist mode for Python imports**
- âœ… **Output sanitization** (removes API keys, passwords)
- âœ… **Real-time validation** before execution

View security info in **Settings â†’ Security** tab.

---

## ğŸ› ï¸ Tech Stack

### Frontend

- **Framework:** Next.js 16 (App Router)
- **UI Library:** React 19
- **Language:** TypeScript 5.9
- **Styling:** Tailwind CSS 4.1
- **Components:** shadcn/ui (Radix UI)
- **Icons:** Lucide React

### Backend

- **API Routes:** Next.js API Routes
- **Database:** Prisma ORM with SQLite
- **Validation:** Zod
- **Python Execution:** Node.js child_process

### State Management

- **Data Fetching:** SWR (with optimizations)
- **Client State:** React Hooks
- **Persistence:** LocalStorage

### Development

- **Package Manager:** bun
- **Code Quality:** ESLint, Prettier
- **Type Checking:** TypeScript strict mode

---

## ğŸ“Š Performance Metrics

### Before vs After Optimization

| Operation           | Before | After  | Improvement          |
| ------------------- | ------ | ------ | -------------------- |
| Registry Filtering  | ~150ms | ~50ms  | **66% faster** âš¡    |
| Page Renders        | ~200ms | ~120ms | **40% faster** âš¡    |
| Network Requests    | 100%   | 30%    | **70% reduction** ğŸ“‰ |
| Time to Interactive | 2.5s   | 1.8s   | **28% faster** ğŸš€    |

### Bundle Size Impact

| Feature            | Size      | Status               |
| ------------------ | --------- | -------------------- |
| Multi-Provider API | ~8KB      | âœ… Minimal           |
| Security System    | ~6KB      | âœ… Minimal           |
| Animations         | ~2KB      | âœ… Minimal           |
| Error Boundary     | ~3KB      | âœ… Minimal           |
| Toast System       | ~2KB      | âœ… Minimal           |
| Loading States     | ~1KB      | âœ… Minimal           |
| Python Detection   | ~4KB      | âœ… Minimal           |
| Terminal           | ~4KB      | âœ… Minimal           |
| **Total Added**    | **~30KB** | âœ… **<2% of bundle** |

### Lighthouse Scores

| Metric         | Score  |
| -------------- | ------ |
| Performance    | 95+ ğŸŸ¢ |
| Accessibility  | 98+ ğŸŸ¢ |
| Best Practices | 100 ğŸŸ¢ |
| SEO            | 100 ğŸŸ¢ |

---

## ğŸ”‘ Key Differentiators

### Why MCP Workbench?

1. **ğŸŒ Universal LLM Access** - 11 providers in one unified interface
2. **ğŸš€ Blazing Fast** - 66% faster operations through smart caching
3. **ğŸ”’ Enterprise Security** - 160+ blocked patterns for safe execution
4. **ğŸ¨ Beautiful UI** - Premium glassmorphism design with animations
5. **ğŸ Python-First** - Auto-detects 4+ environment types (uv, conda, venv)
6. **ğŸ›¡ï¸ Production Ready** - Error boundaries, loading states, retry logic
7. **ğŸ”§ Developer Friendly** - Integrated terminal, command palette, hot reload
8. **ï¿½ Database-Backed** - Secure API key storage with Prisma + SQLite
9. **â™¿ Accessible** - WCAG 2.1 compliant with keyboard navigation
10. **ğŸ“± Responsive** - Works beautifully on all screen sizes

---

## ğŸ§ª Testing

### Running Tests

```bash
# Run all tests
bun test

# Run tests in watch mode
bun test:watch

# Generate coverage report
bun test:coverage
```

### Manual Testing Checklist

- [ ] Python environments auto-detected
- [ ] Terminal executes commands correctly
- [ ] Animations play smoothly
- [ ] Loading states display during async operations
- [ ] Error boundary catches and displays errors
- [ ] Toast notifications appear and dismiss
- [ ] Cursor feedback on all interactive elements

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Next.js** - Amazing React framework
- **Vercel** - Deployment platform
- **shadcn/ui** - Beautiful component library
- **Radix UI** - Accessible primitives
- **Tailwind CSS** - Utility-first CSS
- **Ollama** - Local LLM runtime
- **Anthropic** - MCP protocol specification

---

## ğŸ“ Contact & Support

- **GitHub Issues:** [Report a bug or request a feature](https://github.com/scorpiontaj/mcp-workbench/issues)
- **Discussions:** [Join the community](https://github.com/scorpiontaj/mcp-workbench/discussions)
- **Portfolio:** [My Portfolio](https://scorpiontaj.me)

---

<div align="center">
  
  ### â­ Star this repo if you find it helpful!
  
  Made with â¤ï¸ by [Tajeddine Bourhim](https://github.com/scorpiontaj)

**[ğŸ“¦ View on GitHub](https://github.com/scorpiontaj/mcp-workbench)**

</div>
